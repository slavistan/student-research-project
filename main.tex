\documentclass{article}

% Packages
\usepackage[utf8]{inputenc} % Required for German umlauts
% SVG
\usepackage{svg}
% Bib
\usepackage[backend=biber]{biblatex}
\addbibresource{bib/bibliography.bib}

%%
%% Custom commands
%%

%
% Tikz Setup
%
\usepackage[customcolors]{hf-tikz}

\tikzset{style green/.style={
    set fill color=green!50!lime!60,
    set border color=white,
  },
  style cyan/.style={
    set fill color=cyan!90!blue!60,
    set border color=white,
  },
  style orange/.style={
    set fill color=orange!80!red!60,
    set border color=white,
  },
  hor/.style={
    above left offset={-0.15,0.31},
    below right offset={0.15,-0.125},
    #1
  },
  ver/.style={
    above left offset={-0.1,0.3},
    below right offset={0.15,-0.15},
    #1
  }
}

\author{Stanislaw HÃ¼ll}
\title{Student Research Project}
\date{2018-11-11}
\begin{document}

\maketitle

\section{Introduction}

  \subsection{Compressed Sparse Row Format}
    It is a widely used storage format for sparse matrices which does not make assumptions about the matrix's shape
    or its distribution of non-zero elements in contrast to other popular sparse matrix storage formats such as the
    the diagonal storage format or ELLPACK. It optimizes the storage requirements of general sparse matrices with
    respect to the naive coordinate format (COO) in that each non-zero's row index is no longer explicitly stored.

    The CSR format consists of three dense arrays:

    The values array stores the numerical value for each non-zero entry in the matrix while their column index is stored
    in the associated column-index array. A third array, the row-pointer array, encodes the beginning of each row's
    section within the values and column-index arrays, i.e. it stores the offset of each row's first non-zero element
    into the two previous arrays. Thus the CSR format optimizes the storage requirements of general sparse matrices with
    respect to the naive coordinate format (COO) in that each-nonzero's row index is no longer explicitly stored,
    shrinking the size of the third array from one entry per non-zero element to a single entry per row.

    \input{fig/csr_example.tex}

    By convention, the non-zeros are stored row-wise in ordered fashion from left to right implying that each row's
    section within the column-index array is sorted in ascending fashion. Additionally, the row-pointer array contains
    an additional element denoting the total number of non-zero elements in the structure. Note that sometimes a
    different nomenclature is utilized in the existing literature, referring to the arrays as A (values), JA
    (column-indices) and IA (row-pointers), respectively \cite{sparskit}.

    The CSR format's salient feature is its direct access to a row's non-zero elements' values and column indices making
    it particularly well suited for matrix-vector-multiplication utilizing a conventional row-by-column computation
    scheme. Aside of this feature storing the non-zero elements row by row as opposed to column by column is, to a
    certain degree, arbitrary and thus exist numerical libraries and toolkits such as the Eigen C++ library
    \cite{eigen:website} or the Harwell-Boeing sparse matrix collection \cite{harwell-boeing} which utilize the CSR
    format's conjugate, the compressed sparse column format (CSC), as their default means of representing sparse
    matrices.

  \subsection{Structured Grid Matrices}

    Structured grid computations are ubiquitously used for physical simulations for computational fluid dynamics,
    electrodynamics and astrophysics.  In contrast to unstructured grids the regularity inherent to structured grids
    allows for very efficient numerical treatment, such that even in cases where sufficiently complex geometries
    prohibit the decomposition of the target domain into a single overarching structured grid the domain is often
    tesselated into an unstructured configuration, with the tiles being filled by independent structured grids
    \cite{Badcock2000}.

    To derive an approximate solution to a physical system's set of partial differential equations
    the PDEs are discretized on the structured grid by approximating the differential operators by algebraic
    expressions. A promiment example is the Cartesian finite-difference approximation of the Laplacian operator.
    The discretization step yields a linear problem $A x = b$ in which the right-hand side $b$ depends only on the
    boundary conditions and is thus known.

    (((TODO))) The solution of this linear system by iterative means requires that, starting at an initial guess $x_0$,
    a stencil operation is applied to each node, i.e. its new value is determined by a weighted sum of the current
    values of its adjacent nodes. Which nodes are considered adjacent depends on the approximation of the differential
    operators, but in general the pattern is symmetric with respect to the node in question while the individual weights
    of the weighted sum might change from node to node. The stencil corresponding to the finite-difference Laplacian is
    the symmetric 5-point or 7-point stencil for 2D or 3D grids, respectively.

    The stencil operation across the grid can be expressed in terms of a matrix-vector multiplication, where
    the vector contains the grid nodes' function values and the matrix is the grid's adjacency matrix, whose non-zero
    entries encode the adjacency relation of the stencil across the whole matrix and whose numeric values are the
    weighted sum's weights. These adjacency matrices have a very characteristic structure, whose exact shape depends on
    the type of boundary condition underlying the physical system's PDEs and on the stencil's geometry. In general, they
    are symmetric and consist of as many diagonals as there are nodes in the stencil. The diagonals are almost fully
    dense with exceptions arising at positions corresponding to nodes at the grid's boundaries, where the
    adjacency pattern is disturbed by missing nodes as in the case of Dirichlet boundary conditions. Adjacency matrices
    are symmetric and have one row and column per node in the grid.

    \input{fig/stencil_adj_mat.tex}

    TODO: Bisher nur finite difference, was ist mit FEM?

    Arise as finite difference adjacency matrices from discretization of elliptic type PDE (SPARSKIT 7.1)
      and structured mesh finite element matrices.
    Are (locally) structured.
    "Almost" diagonal --> DIA not the best. [Godwin2013: p9!!!]

\section{Three-fold compressed sparse row}

  Evidently, representing a structured grid's adjacency matrix using the regular CSR format is highly suboptimal, as it
  has no means of capturing the obvious repetetiveness of the structure. While at first glance the diagonal format seems
  to be an appealing choice for the types of matrices introduced in the previous section, real-life problems produce
  matrices which are only locally structured, i.e. they contain multiple fully structured sections corresponding to the
  multiple structured grid regions of the overall heterogeneous domain mentioned above, which need not be aligned in
  a way to produce a diagonal structure at all. Thus a more flexible approach is taken adapting the CSR format.

  Additionally, utilizing a CSR-like format keeps open the possibility to eventually tackle adjacency matrices of
  unstructured grids.

  This section introduces the data layout and storage scheme of the three-fold compressed sparse row format which allows
  for the utilization of certain compression mechanisms explained thereafter. Finally, the algorithms required to
  perform common arithmetic operations are presented.

  \subsection{Data layout and storage scheme}

    The basic motive of this work is to leverage the regularity inherent in structured grid adjacency matrices. The vast
    majority of the matrix's rows share a common column index pattern. Their non-zero elements occur at fixed offsets
    with respect to the row's first non-zero element's position.

      ((( TODO: Bild )))

    It is cruicial to observe that, in the most general case, the index patterns' regularity is not shared by the
    non-zero elements' numerical values. While two or more rows may share the same pattern their corresponding values
    need not be similar to each other at all and, possibly, even vice versa. To prevent that a lack of common regularity
    impedes optimizing the layout of one or the other it is hence necessary to decouple the representation of a row's
    column index positions from the representation of its numerical values. The C3SR format accounts for this
    circumstance and maintains separate data structures for the patterns and values.

    The values are represented by two arrays which utilize the CSR's basic idea of storing all relevant data in an
    array (V) and managing a separate start-index array (VS) pointing each row's section's first element.

      ((( TODO: Bild. Einfache matrix mit values )))

    The column indices are stored abiding by the same principle with the additional detail that each row's column
    indices are decomposed into the absolute index of the row's first non-zero element, which is referred to as the
    row's 'peg', and the relative offsets of the remaining non-zeros' column indices with respect to the peg index.
    This introduces a degree of freedom whose usefulness will become evident in the context of compression. Thus the
    column indices are encoded into an array storing the patterns (J), another array storing the peg index (JP)
    and an index pointer array (JS) into J in the same way that VS relates to V.

      ((( TODO: Bild )))

    A sixth and final array (RS) is used to store the number of non-zeros in each row of the matrix in order to know the
    size of the row's section within the pattern array and the values array. While the respective start index-pointer
    arrays store the section's first element's index they cannot encode the size of the section. Prior to compressing
    the size of a row can indeed be retrieved from the corresponding start index-pointer array in the same way the CSR
    format's row size may be retrieved from the row-pointer array by taking the difference between the row's entry and
    its successor. However, this requires that the row's sections are stored contiguously in the arrays and this
    property is lost during compression as will be explained in the next section.

    Summarizing the data organization of the C3SR format:
    \begin{itemize}
      \item Data representing the matrix's non-zero elements: V, VS
      \item Data representing non-zero elements' column indices: J, JP, JS
      \item Array containing information about the row sizes: RSS
    \end{itemize}

  \subsection{Compression mechanism}

    Using this storage scheme the column index information may be compressed by removing duplicate patterns from J and
    updating the start-index pointers JS of such duplicate rows to point the start of the corresponding unique section
    within J.

      ((( TODO: Bild )))

    The information about the non-zeros' values can be compressed in precicely the same way: Duplicate sections within V
    corresponding to different rows with identical values are removed and the corresponding start pointers are updated.

    In theory, the compression of patterns and values are orthogonal operations and if the overall goal were to minimize
    the storage requirement of a C3SR object in memory the best advice would be to exploit duplication in the matrix as
    much as possible. However, efficient arithmetic requires considerations going beyond maximum compression such as
    parallel performance and parallel scalability implying that the implementation must heed the principles of
    data locality and independence of tasks in the control flow of the algorithm. Such details are delayed until the
    pertinent algorithms are discussed in detail.

    Note that this section avoids reasoning about low-level details for the sake of clarity. Tweaks such as the omission
    of each pattern's first value, which is always zero or mapping two partially matching rows' sections within J onto
    each other for a little gain in storage space optimization are considered implementation details are are not discussed
    here.

  \subsection{Algorithms}

    Stencil operation is applied multiple times during the solution, thus matvecmult speed is critical.

    \subsubsection{Matvecmult}

      improves locality (--> Performance)

    \subsubsection{Element access A[i;j]}
      binary lookup
\section{Performance Benchmarks}
  Measure performance in terms of (1) data compression ratio and (2) arithmetic performance (matvecmult)

  \subsection{Generation of structured grid adjacency matrices as test matrices}

  \subsection{Data compression}

  \subsection{Arithmetic performance (matvecmult)}

\section{Summary}
  Advantages: General purpose, good performance, parallel scalability
  Disadv: Static structure (cannot add/remove elements)

\printbibliography
\end{document}
