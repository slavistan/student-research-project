\documentclass{article}

% Packages
%\usepackage[utf8]{inputenc} % Required for German umlauts
\usepackage{amsmath, bm}
% SVG
\usepackage{svg}
% Bib
\usepackage[backend=biber]{biblatex}
\addbibresource{bib/bibliography.bib}
% Geometry
\usepackage{geometry}
\geometry{
  paper=a4paper, % Change to letterpaper for US letter
  inner=2.5cm, % Inner margin
  outer=3.8cm, % Outer margin
  bindingoffset=.5cm, % Binding offset
  top=1.5cm, % Top margin
  bottom=1.5cm, % Bottom margin
}
\usepackage[onehalfspacing]{setspace}
\usepackage{parskip}
%
\usepackage{enumitem} % description alignment

%
% Tikz Setup
%
\usepackage{tikz}
\newcommand{\tikzmark}[2]{
    \tikz[overlay,remember picture,baseline]
    \node[anchor=base] (#1) {$#2$};
}
\usetikzlibrary{positioning}
%
% Font
%
\usepackage{fontspec}
\setmainfont{Palatino Linotype}
%
% Custom commands
%
\input{commands.tex}

%%%%%%%
%%%%%%% Begin of document
%%%%%%%

\author{Stanislaw HÃ¼ll}
\title{Student Research Project}
\date{2018-11-11}
\begin{document}

\maketitle

\section{Introduction}

  \subsection{Compressed Sparse Row Matrix Storage Format}

    The compressed sparse row (CSR) format is a widely used storage format for sparse matrices. Unlike other popular sparse matrix storage formats such as the diagonal storage format (DIA) the CSR format is not tailored to any special type of matrix but is a general purpose storage format which makes no assumptions about the matrix's shape or its distribution of non-zeros. The CSR format can be considered an improvement to the naive coordinate format (COO) in that each non-zero's row index is no longer explicitly stored \cite{Bell2011}.

    The CSR format consists of three dense arrays. The values array (V) stores the numerical value for each non-zero entry in the matrix while the associated column index is stored in the column-index array (CI). A third array, the row-pointer array (RP), encodes the beginning of each row's section within the values and column-index arrays, i.e. it stores the offset of each row's first non-zero element into the two arrays. By convention the row-pointer array usually also contains an additional element denoting the total number of non-zero elements in the matrix. An example for the CSR format is given in Figure \ref{fig:csr_example}.

    \begin{figure}[ht]
      \centering
      \begin{minipage}{0.4\textwidth}
        \centering
        $$
        \begin{pmatrix}
          \color{red}{\bm{3}} &                     0 &  \color{red}{\bm{4}} &                    0 \\
                            0 & \color{green}{\bm{1}} &                    0 &                    0 \\
                            0 &                     0 & \color{blue}{\bm{7}} & \color{blue}{\bm{8}} \\
        \end{pmatrix}
        $$
      \end{minipage}
      \begin{minipage}{0.4\textwidth}
        \centering
        $$
        \begin{matrix}
          \text{Values}  & : & \color{red}{3} &   \color{red}{4} & \color{green}{1} & \color{blue}{7} & \color{blue}{8} \\
          \text{Column-Indices} & : & \color{red}{0} &   \color{red}{2} & \color{green}{1} & \color{blue}{2} & \color{blue}{3} \\
          \text{Row-Pointers} & : & \color{red}{0} & \color{green}{2} &  \color{blue}{3} &               5 &                 \\
        \end{matrix}
        $$
      \end{minipage}
      \caption{\textbf{Exemplary matrix with corresponding CSR representation.} The array elements are color-coded in red for the first row, green for the second row and blue for the third row.}
      \label{fig:csr_example}
    \end{figure}

    Thus, as previously mentioned, the CSR format optimizes the storage requirements of general sparse matrices with respect to the naive coordinate format (COO) shrinking the size of the third array from one entry per non-zero element to a single entry per row irrespective of the row's number of non-zeros. Furthermore, the existing literature, in part, utilizes a different nomenclature referring to the arrays as A (values array), JA (column-index array) and IA (row-pointer array), respectively \cite{sparskit}.

    The CSR format's salient feature is the contiguousness of the rows' non-zero elements' values and column indices making it particularly well suited for matrix-vector-multiplication utilizing a conventional row-by-column computation scheme due to ideal data locality. Aside of this characteristic storing the non-zero elements row-by-row as opposed to column-by-column is, to a certain degree, arbitrary and thus exist numerical libraries and toolkits such as the Eigen C++ library \cite{eigen:website} or the Harwell-Boeing sparse matrix collection \cite{harwell-boeing} which utilize the CSR format's conjugate, the compressed sparse column format (CSC), as their default means of storing sparse matrices.

    The CSR format serves as a starting point for the C3SR sparse matrix storage format for structured grid matrices which is the focal point of this work.

  \subsection{Structured Grid Matrices}

    Structured grid computations are ubiquitously used for physical simulations in scientific fields such as, for example, computational fluid dynamics, electrodynamics and astrophysics. Generally, a system of partial differential equations is solved by discretization and linearization of the problem which involves generating a grid corresponding to the physical domain in question. A structured grid refers to a mesh whose nodes are logically rectangular, i.e. they are uniquely identified by a tuple of coordinates and v.v., such as $(i, j, k)$ for three dimensions (Figure \ref{fig:structured_grid_example}).

    \begin{figure}[ht]
        \centering
        \vspace{0.5cm}
        \begin{minipage}{0.4\textwidth}
          \centering
          \includegraphics[width=0.9\textwidth]{fig/structured_grid_example.png} % second figure itself
          \caption{\textbf{Curvi-linear grid over a physically complex domain.} The grid nodes are logically rectangular despite the non-rectangular physical domain and thus comprise a structured grid. Source: \cite{daad:website}}
          \label{fig:structured_grid_example}
        \end{minipage}\hfill
        \begin{minipage}{0.5\textwidth}
          \centering
          \includegraphics[width=0.9\textwidth]{fig/refined_structured_grid.png} % second figure itself
          \caption{\textbf{Heterogeneous mesh with structured regions.} Outer side (green) and interior volume are fully structured and are connected via an unstructured mesh region. Given proper indexing of grid nodes the resulting sparse matrix will exhibit regularity in the sections pertaining to the structured mesh region. Source: \cite{cubit-mesh-refinement:website}}
          \label{fig:refined_structured_grid}
        \end{minipage}
    \end{figure}

    In contrast to unstructured grids the regularity inherent to structured grids allows for very efficient numerical treatment, such that even in cases where sufficiently complex geometries prohibit the decomposition of the target domain into a single overarching structured grid the domain is often tesselated into an unstructured configuration, with the tiles being filled by independent structured grids \cite{Badcock2000}(Figure \ref{fig:refined_structured_grid}).

    \begin{figure}
        \centering
        \begin{minipage}{0.45\textwidth}
          \centering
          \input{fig/laplacian_example.tikz}
        \end{minipage}\hfill
        \begin{minipage}{0.45\textwidth}
            \centering
            \includegraphics[width=0.9\textwidth]{fig/laplacian_example.png} % second figure itself
        \end{minipage}
        \caption{\textbf{Structured grid and corresponding sparse adjacency matrix for a simple Laplacian} $\nabla^2 u(\vec{r}) = 0$. The Laplace-operator is approximated by the conventional 3-axial symmetric discretization scheme, equivalent to a symmetric 7-point stencil operation.}
        \label{fig:laplacian_example}
    \end{figure}

    The solution procedure yields a sparse linear system whose solution is approximated by iterative methods involving repeated sparse matrix-vector-multiplications $Ax = b$ where the matrix $A$ encodes the adjacency structure of the grid. For a structured grid the resulting matrix's distribution of non-zeros has a very distinct pattern. Generally speaking, such matrices consist of multiple diagonals of non-zero values at fixed intervals while all other elements are zero. The diagonals are almost fully dense with exceptions arising at positions corresponding to nodes at the grid's boundaries, where the regular adjacency pattern of the grid is disturbed by missing nodes. A grid and its corresponding sparse matrix's structure are depicted in Figure \ref{fig:laplacian_example} for a simple Laplacian problem.

    The matrix's non-zero values depend on the underlying physical problem's parameters, the type of PDE and the differential operators' discretization schemes. In general, the non-zeros' numeric values are independent from their location within the matrix but there exist classes of problems where the equivalence of the structure of a set of matrix rows also implies that those rows' non-zeros share the same numeric values. Furthermore, solving problems on higher-dimensional entities such as vectors or matrices yields structured grid matrices whose 'elements' are themselves square matrices \cite{Godwin2013}.

    The sparse matrices relevant to this work areany sparse matrices which contain one or more sets of rows whose non-zero's column indices are identical save for a fixed offset. Structured grid matrices arising from the procedure mentioned above have one such set to which the overwhelming majority of rows belong corresponding to all inner grid nodes (such as in the example in Figure \ref{fig:laplacian_example}). However, all of the ideas presented hereinafter may be applied to any sparse matrix whose structure exhibits any degree of repetiveness.

\section{Threefold Compressed Sparse Row Sparse Matrix Storage Format (C3SR)}

  Evidently, representing a structured grid matrix using the regular CSR format is highly suboptimal, as it has no means of capturing the apparent repetetiveness of the structure. While at first glance the diagonal format might seem an appealing choice for the types of matrices introduced in the previous section, real-life problems produce matrices which are possibly only locally structured, i.e. they contain multiple fully structured sections corresponding to the multiple structured grid regions of the overall heterogeneous domain (Figure \ref{fig:refined_structured_grid}), which need not be aligned in a way to produce a diagonal structure at all. For such matrices the diagonal storage format is highly suboptimal \cite{Bell2011}. Thus a more flexible approach is taken adapting the CSR format to suit the characteristics of structured grid matrices.

  This section introduces the data layout and the matrix-vector multiplication scheme of the threefold compressed sparse row matrix storage format (C3SR). Its aim is to optimize arithmetic performance of matrix-vector multiplications involving structured grid matrices by improving data locality through a structurally-aware space-saving storage scheme and by implementing an efficient arithmetic scheme capable of profiting from modern computer architectures' hardware assets.

  \subsection{Data layout and storage scheme}

    It is cruicial to observe that, in the most general case, the index patterns' regularity is not shared by the non-zero elements' numerical values. While two or more rows may share the same pattern their corresponding values need not be similar to each other at all. To prevent that a lack of common regularity impedes optimizing the storage requirements of one or the other it is hence necessary to decouple the representation of a row's non-zeros column index positions from the representation of their numerical values. The C3SR format accounts for this circumstance and maintains separate data structures for the non-zeros' column indices and their values.

    Based on the observation that structured grid matrices contain many rows whose non-zeros are located at the same positions except for a possible offset the C3SR format decomposes the column-index positions into the column index of the row's first non-zero element, referred to as the row's peg hereinafter, and the relative column indices of all of the row's non-zeros with respect to the first non-zero's column index, i.e. the relative offsets with respect to the peg index. The latter column index offsets relative to the peg index shall be called the row's column index pattern, or simply the row's pattern. Naturally, only unique patterns are stored, drastically shrinking the storage requirements of such matrices whose majority of rows exhibit the same pattern.

    Thus, in order to represent the column indices of a matrix row's non-zeros the C3SR format utilizes three arrays:

    \begin{description}[align = left, labelwidth = 4cm]
      \item [JP - \emph{Peg column index}] \hfill \\
        Column index of each row's first non-zero. One element per row in matrix.
      \item [J - \emph{Column index patterns}] \hfill \\
        Column index position offsets of the rows' non-zeros relative to peg column index for each row. Only unique patterns are stored.
      \item [JS - \emph{Pattern index pointer}] \hfill \\
        Index pointer to each row's first element within \J. One element per row in matrix.
    \end{description}

    \begin{figure}[ht]
      \centering
      \begin{minipage}{0.4\textwidth}
        \centering
        $$
        \begin{pmatrix}
          0 & \bullet & 0 & \bullet & \bullet & 0 \\
          0 & \bullet & 0 & 0 & \bullet & 0 \\
          0 & 0 & \bullet & 0 & \bullet & \bullet \\
        \end{pmatrix}
        $$
      \end{minipage}
      \begin{minipage}{0.4\textwidth}
        \centering
        $$
        \begin{matrix}
          \JP & : & 1 & 0 & 2 &   &   \\
           \J & : & 0 & 2 & 3 & 0 & 3 \\
          \JS & : & 0 & 3 & 0 &   &   \\
        \end{matrix}
        $$
      \end{minipage}
      \caption{\textbf{Matrix with corresponding C3SR representation (structural information only).} The non-zeros are denoted as black dots. The $0^{\text{th}}$ and $2^{\text{th}}$ row exhibit the same column index pattern $\big(0,2,3\big)$ at different peg index positions of $1$ and $2$, respectively, thus the $0^{\text{th}}$ and the $2^{\text{th}}$ element of \JS point \J[0], which is the first element of this unique pattern. The $1^{\text{th}}$ row has a unique pattern which is stored after the previous pattern within \J at offset $3$ which \JS[1] accordingly points.}
      \label{fig:c3sr_example_structure}
    \end{figure}

    The matrix's non-zeros' numerical values are represented using two dense arrays \V, which contains the values and \VS, the index-pointer into \V which relates to \V in the same way \JS relates to \J. If multiple rows exhibit the same pattern and their values match at the same time the values are stored only once within \V which allows for efficient matrix-vector multiplication schemes shown below.

    \begin{description}[align = left, labelwidth = 4cm]
      \item [\V - \emph{Values}] \hfill \\
        Non-zeros' numerical values. Duplicates across rows with same pattern are stored only once.
      \item [\VS - \emph{Values Index Pointer}] \hfill \\
        Index pointer to each row's first element within \V. One element per row in matrix.
    \end{description}

    A sixth and final array \RSS stores the number of non-zeros in each row of the matrix. This information is required as the index-pointer arrays \JS and \VS point a row's first element within \J and \V but may not contain the information about how long the segment pertaining to the row within those arrays.

    \begin{description}[align = left, labelwidth = 4cm]
      \item [\RSS - \emph{Row Size}] \hfill \\
        Number of non-zeros for each row. One element per row in matrix.
    \end{description}

    Summarizing the data organization of the C3SR format:

    \begin{itemize}
      \item Data representing the matrix's non-zero elements: V, VS
      \item Data representing non-zero elements' column indices: J, JP, JS
      \item Array containing information about the row sizes: RSS
    \end{itemize}

    /TODO? Nomenclature section after abstract?

  \subsection{Compression mechanism}

    Using this storage scheme the column index information may be compressed by removing duplicate patterns from J and
    updating the start-index pointers JS of such duplicate rows to point the start of the corresponding unique section
    within J.

      ((( TODO: Bild )))

    The information about the non-zeros' values can be compressed in precicely the same way: Duplicate sections within V
    corresponding to different rows with identical values are removed and the corresponding start pointers are updated.

    In theory, the compression of patterns and values are orthogonal operations and if the overall goal were to minimize
    the storage requirement of a C3SR object in memory the best advice would be to exploit duplication in the matrix as
    much as possible. However, efficient arithmetic requires considerations going beyond maximum compression such as
    parallel performance and parallel scalability implying that the implementation must heed the principles of
    data locality and independence of tasks in the control flow of the algorithm.

    (((TODO: Partitioning during compression + stable- and non-stable values compression)))

    Note that this section avoids reasoning about low-level details for the sake of clarity. Tweaks such as the omission
    of each pattern's first value, which is always zero or mapping two partially matching rows' sections within J onto
    each other for a little gain in storage space optimization are considered implementation details are are not discussed
    here.

  \subsection{Matrix-Vector Multiplication}

    \subsubsection{Basic CSR Multiplication scheme}

      Algorithmically, the basic multiplication schemes of the C3SR format and the CSR format are very similar. Both access their respective non-zeros by an index pointer into an array and compute the argument vector's access index in the same manner. Differences arise only in the C3SR's additional offset $\JP[k]$ which is applied to each relative column index.

      C3sr:
      $$\sum \limits_{\alpha = 0}^{\RSS[k] - 1} \V[\VS[k] + \alpha] \cdot x[\J[\JS[k] + \alpha] + \JP[k]]$$

      CSR:
      $$\sum \limits_{\alpha = 0}^{\RP[k] - 1} \V[\RP[k] + \alpha] \cdot x[\CI[\RP[k] + \alpha]]$$

      However, the fact that the C3SR format utilizes additional data structures to store information leads to additional accesses to memory. Assuming the general case of a large matrix devoid of any regularity in its structue whose size exceeds the machine's cache the CSR format's arithmetic performance will be better proportional to the reduction of loads from memory with respect to the C3SR format as this is a memory bound computation involving few trivial arithmetic operations.

      On the flipside, structured matrices facilitate an optimized representation allowing a small segment of memory, corresponding to possibly only a few cache lines, to contain the matrix's complete structural information. This can drastically improve arithmetic performance of the C3SR format despite the more complex memory access scheme, as will be shown in the benchmark section.

    \subsubsection{SIMD Implementation}

      In addition to the performance gain utilizing the basic multiplication scheme, the data layout of a structured matrix in C3SR format allows for the matrix-vector multiplication to be implemented in such a way, as to utilize SIMD parallelism. The matrix's data is layed out in memory in such a way that the matrix-vector multiplication may be performed for multiple rows at a time using vectorization. Depending on the composition of the matrix three different, yet very similar, multiplication schemes can be devised.

      Suppose that a horizontal slice of rows $r, \ldots, r+k$ has diagonal structure with the diagonals starting at indices $s, t, \ldots, u$, such as is depicted in TODO. The matrix-vector multiplication for each of the slice's rows is composed of the same number of summands, one per diagonal. Each of the summands is a product of the diagonal's non-zero entry and the argument's corresponding element, starting out with $a_{r,s} \cdot x_s$ for the first diagonal's initial element and $a_{r,t} \cdot x_t$ for the second diagonal. For each subsequent row the matrix element's indices are incremented aswell as the argumnet vector's index, commencing with $a_{r+1, s_1} \cdot x_{s+1}$ for the first diagonal's second element and accordingly for each other diagonal.

      As each diagonal's summand accesses the argument vector's elements in consecutive fashion, for example $x_s, x_{s+1}, \ldots, x_{s + k}$ for the first diagonal, the multiplication can be vectorized. The other summand's constituents, the diagonal's matrix entries, are accessed at a fixed offset which is equal to the number of diagonals. This is due to the fact that the matrix slice's non-zero elements are stored row-by-row, where each row has the same number of elements. Thus $a_{r,s}$ is located as many elements before $a_{r+1, r+2}$ within \V as there are diagonals. 

      \begin{equation}
        \begin{pmatrix}
          \\
          \cdots & 0 & \tikzmark{diagAFirst}{a_{r,s}} &  0 & \cdots & \tikzmark{diagBFirst}{a_{r,t}} & 0 & \cdots & \cdots & \cdots \\
          \cdots & \cdots & 0 & a_{r+1,s+1} & 0 & \cdots & a_{r+1,t+1} & 0 & \cdots & \cdots \\
          \cdots & \cdots & \cdots & 0 & \tikzmark{diagALast}{a_{r+2,s+2}} & 0 & \cdots & \tikzmark{diagBLast}{a_{r+2,t+2}} & 0 & \cdots \\
          \\
        \end{pmatrix}
      \end{equation}

      \begin{tikzpicture}[overlay,remember picture]
           \draw[color=red,opacity=0.1,line width=1mm,line cap=round] (diagAFirst.center) -- (diagALast.center);
           \draw[color=green,opacity=0.1,line width=1mm,line cap=round] (diagBFirst.center) -- (diagBLast.center);
      \end{tikzpicture}

      \begin{equation}
        \begin{matrix}
          \begin{bmatrix}
            a_{r,s}     \\
            a_{r+1,s+1} \\
               \vdots   \\
            a_{r+k,s+k} \\
          \end{bmatrix} & \cdot & \begin{bmatrix}
                                    x_s      \\
                                    x_{s+1}  \\
                                      \vdots \\
                                    x_{s+k}  \\
                                  \end{bmatrix} & + & \begin{bmatrix}
                                                      a_{r,t}     \\
                                                      a_{r+1,t+1} \\
                                                        \vdots    \\
                                                      a_{r+k,t+k} \\
                                                      \end{bmatrix} & \cdot & \begin{bmatrix}
                                                                                x_t \\
                                                                                x_{t+1} \\
                                                                                \vdots \\
                                                                                x_{t+k}
                                                                              \end{bmatrix} & + & \cdots & = \begin{bmatrix}
                                                                                                                 y_{r} \\
                                                                                                                 y_{r+1} \\
                                                                                                                 \vdots \\
                                                                                                                 y_{r+k}
                                                                                                                \end{bmatrix}
        \end{matrix}
      \end{equation}

      In SIMD terms a stride-gather and a load is required for the diagonal's elements and the argument vector, respectively. The two vector registers are then multiplied and the result is then added onto the product pertaining to the next diagonal, as depicted in TODO.

      For the case of a matrix slice whose structure is diagonal and whose values within each diagonal are identical, e.g. $a_{r,s} = a_{r+1, s+1} = \ldots$ for the first diagonal etc., the multiplication scheme is simplified in that the argument vector's values contained in the vector register are simply scaled by the diagonal's value instead of being subjected by a vectorized multiplication.

      \begin{equation}
        \begin{matrix}
          a_{r,s} & \cdot & \begin{bmatrix}
                                    x_s      \\
                                    x_{s+1}  \\
                                      \vdots \\
                                    x_{s+k}  \\
          \end{bmatrix} & + & a_{r,t} & \cdot & \begin{bmatrix}
                                                x_t \\
                                                x_{t+1} \\
                                                \vdots \\
                                                x_{t+k}
                                                                              \end{bmatrix} & + & \cdots & =  \begin{bmatrix}
                                                                                                                 y_{r} \\
                                                                                                                 y_{r+1} \\
                                                                                                                 \vdots \\
                                                                                                                 y_{r+k}
                                                                                                                \end{bmatrix}
        \end{matrix}
      \end{equation}

      Another practically relevant case are matrix slices whose structure is uniform, i.e. each row's non-zero elements are situated at the same columns. The corresponding vectorized matrix-vector multiplication scheme is again similar to the general case of a diagonal structure. Here the argument vector's elements serve as scaling constants for the vector register containing the matrix's elements, which are again located at fixed offsets within \V  as depicted in TODO.

      \begin{equation}
        \begin{pmatrix}
          \\
          \cdots & 0 & a_{r,s} &  0 & \cdots & a_{r,t} & 0 & \cdots \\
          \cdots & 0 & a_{r+1,s} & 0 & \cdots & a_{r+1,t} & 0 & \cdots \\
          \cdots & 0 & a_{r+2,s} & 0 & \cdots & a_{r+2,t} & 0 & \cdots \\
          \\
        \end{pmatrix}
      \end{equation}

      \begin{equation}
        \begin{matrix}
          \begin{bmatrix}
            a_{r,s}     \\
            a_{r+1,s+1} \\
               \vdots   \\
            a_{r+k,s+k} \\
          \end{bmatrix} & \cdot & x_s & + & \begin{bmatrix}
                                              a_{r,t}     \\
                                              a_{r+1,t+1} \\
                                                \vdots    \\
                                              a_{r+k,t+k} \\
                                            \end{bmatrix} & \cdot & x_t & + \cdots & = \begin{bmatrix}
                                                                                       y_{r} \\
                                                                                       y_{r+1} \\
                                                                                       \vdots \\
                                                                                       y_{r+k} \\
                                                                                     \end{bmatrix}
        \end{matrix}
      \end{equation}

      All of the above mentioned arithmetic schemes can be extended to vector registers of arbitrary length and are thus theoretically able to scale with additional hardware cabalities.

\section{Performance Benchmarks}
  Measure performance in terms of (1) data compression ratio and (2) arithmetic performance (matvecmult)

  \subsection{Generation of structured grid adjacency matrices as test matrices}

    For the purpose of gauging the performance test matrices are created in CSR format which are then converted to C3SR
    format and compressed. These matrices resemble the structure of the structured grid matrices introduced above and
    are created by iterating through a 3D grid of fixed integral dimensions X, Y, Z and applying a given stencil
    which encodes the desired adjacency relationship. Nodes requested by the stencil but missing from the grid, i.e.
    nodes on the grid's outer borders are omitted, i.e. their corresponding entries in the adjacency matrix carry a zero
    which is equivalent to Dirichlet-type boundary conditions.

    The matrix's non-zero entries' numeric values are obtained from evaluating a sinusoidal function at the geometric
    center point $\vec{r} = (x, y, z)$ inbetween the two nodes in question whereby each Cartesian component $x, y, z$ is
    scaled by its coordinate's span $X, Y, Z$. An additional offset serves to prevent that entries in the matrix
    correponding to adjacent nodes according to the stencil incidentally evaluate to 0. The function utilized is
    $$W(x,y,z; n_x, n_y, n_z) = 2 + \sum \limits_{d \in \{x,y,z\}} \sin{\frac{d}{d_{\text{max}}} \cdot \pi \cdot n_d} $$
    where $n_x, n_y, n_z$ are periodicity parameters for each dimensions.

    Note that $n_d = 0 \Leftrightarrow \partial_d W(\vec{r}) \equiv 0$, introducing a periodicity in the corresponding
    dimension $d$. This feature is utilized to control the periodicity in the matrix's values.

    (((Example of matrix + Computation of nonzeros)))

    For the purpose of this work two different sets of parameters are utilized generating two different matrices: A smaller matrix generated from a $100 \times 100 \times 100$ grid with the periodicities $n_x = n_y = n_z = 0$ and a second, larger matrix based on the same grid but different periodicities $n_x = 1.1; n_y = 1.2; n_z = 1.3$. Both matrices are generated from a symmetric 7p-stencil.

    The matrices' stats are displayed:

    \begin{tabular}{ l c c }
             & Small & Large \\
      \hline                        \\
      V      & 135    & 6940000 \\
      VS     & 1000000 & 1000000 \\
      J      & 135    & 135 \\
      JS     & 1000000 & 1000000 \\
      JP     & 1000000 & 1000000 \\
      RSS    & 1000001 & 1000001 \\
    \end{tabular}

    Note that the ... Daten unterscheiden sich nur in V (--> selbe struktur)
    --> SIMD Multiplikation verwendet bei den Matrizen unterschiedliche implementierungen (s. SIMD arithmetik)
  \subsection{Data compression}

    This plot compares the number of array elements required in the C3SR format to store a fully structured matrix's column index information (green curve) against the baseline size of the equivalent CSR format matrix's column index array (red curve) depending on the partition size utilized for the structural compression. The C3SR format's recorded number of elements comprises the sum of the sizes of the J, JP and JS arrays, respectively. The RS array and the CSR format's row-pointer array are left out of the consideration as they are identical in size. The underlying $50 \times 50 \times 50$ grid contains $125000$ nodes to which the symmetric 7-pt stencil is applied. The numerical values of the matrix are of no concern for its structure.

    The C3SR format's diminishing storage requirements are caused solely by J (blue curve) as JS and
    JP are constant in size, each containing $125000$ elements, one per matrix row. The size of J
    exhibits an inverse linear relationship to the partition size, as can be inferred from the
    straight line's gradient in the double logarithmic plot. This is due to the fact that large
    grids mainly consist of inner nodes whose corresponding rows in the matrix all share the same pattern. Hence the overwhelming majority of partitions' column index information will condense to 7 elements within J (and one element per row for JS and JP) irrespective of the partition size with exceptions arising only around the few border nodes and their corresponding rows.

    The minimum size of J is determined by the matrix's unique patterns which correspond to 8 corner
    nodes a 4 adjacent nodes, 12 edge nodes a 5 adjacency nodes, 6 face nodes a 6 adjaceny nodes and
    the inner nodes with the full 7 adjacency nodes totalling $135$ entries. (TODO: Tikz 3d-draw
    representative of all nodes creating unique patterns).

    TODO: AusreiÃer erklÃ¤ren.
    \begin{figure}[ht]
      \centering
      \includegraphics[width=0.8\textwidth]{fig/structural-compression}
      \caption*{TODO}
    \end{figure}

    //TODO: Structural compression mit interleaved matrices

  \subsection{Arithmetic Performance of Matrix-Vector Multiplication}

    As this is a memory bound operation it is to be expected that the efficacy of simd parallism increases as the object size decreases.

    \begin{figure}[!ht]
      \centering
      \includegraphics[width=0.9\textwidth]{assets/arithmetic_performance}
      \caption{Arithmetic Performance}
    \end{figure}

\section{Summary}
  Advantages: General purpose, good performance, parallel scalability
  Disadv: Static structure (cannot add/remove elements)

OVERALLTODO:
  TODO: ... will be referred to as 'structured matrix' ==== adjacency matrix of structured grids assuming xyz-indexing

  "No need to fully compress the matrix" --> Diminishing returns; parallelizability

  TODO:
    - AbschÃ¤tzung Performance-Gain vs. Speicherzugriffe/MatrixgrÃ¶Ãe
    - KNL Cores haben simple Hardware --> Effekt von korrektem Code ist grÃ¶Ãer
    - KNL: Falls Chunks zu groÃ werden fÃ¤llt Working Set aus Cache
    - Wozu Partitionierung --> Threads kÃ¶nnen parallel arbeiten
    - Throughput-AbschÃ¤tzung (Bewegte Datenmenge aus DRAM / Dauer); A,x,y (jedes Element wird ~1 mal ausgelesen)
    - RSS --> RS

\printbibliography
\end{document}
